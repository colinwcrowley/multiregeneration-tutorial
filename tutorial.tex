\documentclass[12pt]{article}
\usepackage[margin=1.1in]{geometry}

\usepackage{enumerate,amsmath,amsthm,amssymb,amsfonts,mathtools}
\usepackage{xcolor}
\usepackage{listings}
\usepackage{framed}

\usepackage{url}
\definecolor{hot}{RGB}{65,105,225}
\usepackage[pagebackref=true,colorlinks=true, linkcolor=hot ,  citecolor=hot, urlcolor=hot]{hyperref}%make all the references and links clickable

\newtheorem{theorem}{Theorem}[section]
\theoremstyle{definition} 
\newtheorem{remark}{Remark}[section]

\title{\large \bf
Multiregeneration Tutorial
}
\author{}
\newcommand{\norm}[1]{\left\lVert#1\right\rVert}                                                                                                      
    
\newcommand{\R}{\mathbb{R}}
\newcommand{\Div}{\text{Div}}
\newcommand{\Hom}{\text{Hom}}
\newcommand{\Jac}{\text{Jac}}
\newcommand{\Deg}{\text{Deg}}
\newcommand{\rk}{\text{rk}\ }
\newcommand{\coker}{\text{coker}\ }
\newcommand{\Princ}{\text{Princ}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\PP}{\mathbb{P}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\F}{\mathbb{F}}
\newcommand{\V}[1]{\mathbf{#1}}
\newcommand{\Spt}{\text{support}}

% Colors
\newcommand{\red}[1]{{\color{red}#1}}
\newcommand{\blue}[1]{{\color{blue}#1}}
\newcommand{\magenta}[1]{{\color{magenta}#1}}

\begin{document}
\maketitle
\begin{abstract} 
\red{Insert abstract}
\end{abstract}

\section{Getting Started}
\subsection{Input files}
Say that we are given the following two polynomials
in the variables $x,y$. 
\begin{align*}
    f_1 &= (x-1)(y-3)\\
    f_2 &= (x-2)(y-4)\\
\end{align*}
% Our goal is to describe algorithmically all points in the set 

% \[
%     \mathcal{V}(f_1, f_2) = \{(z_1,z_2) \in \C^2 : f_1(z_1, z_2) = 
%     f_2(z_1, z_2) = 0\}
% \]
% which we call the \emph{zero locus} or the \emph{vanishing} of $f_1$ and 
% $f_2$. \\
\noindent 
By inspection, we see that the set of solutions consists of two points $\{ (1,4), (2,3)\}$.
To solve the system above using the multiregeneration software, let's change into the folder 
``getting-started'', which contains the following four files.\\

\noindent \textbf{bertiniInput\_variables}


\begin{leftbar}
\vspace{-10pt} 
\begin{verbatim}
    variable_group x,y; 
\end{verbatim}\vspace{-10pt} 
\end{leftbar}

\noindent \textbf{bertiniInput\_equations}


\begin{leftbar}
\vspace{-10pt} 
\begin{verbatim}
    function f1,f2;
    f1 = (x-1)*(y-3);
    f2 = (x-2)*(y-4);
\end{verbatim}\vspace{-10pt} 
\end{leftbar}


\noindent \textbf{inputFile.py}

\begin{leftbar}
\vspace{-10pt} 
\begin{verbatim}
    degrees = [[2], [2]]
\end{verbatim}\vspace{-10pt} 
\end{leftbar}

The first three files (those with the prefix ``bertiniInput'') are 
written in the C-like syntax used by the bertini software. 

The last 
file, ``inputFile.py'', contains the additional data that this 
program needs, namely degree information. 
The variable ``degrees'' must be initialized to a list of lists, where 
the $j$'th element of the $i$'th list is the degree of the $i$'th 
function in the $j$th ``variable group.'' For this example there is only 
one variable group consisting of $x,y$, and each function has degree two 
in this variable group. Therefore we use the python syntax
%
\begin{leftbar}
\vspace{-10pt} 
\begin{verbatim}
    degrees = [[2], [2]]
\end{verbatim}\vspace{-10pt} 
\end{leftbar}
\noindent to create a list of two lists, where the single element of the first 
list is the degree of $f_1$ and the single element of the second list is 
the degree of $f_2$.

% The variable ``workingDirectory'' tells the program the name of the 
% folder where it should write the output. If we run the program a second 
% time, then a folder of that name will already exist, and it will be 
% deleted before anything else happens.

\begin{remark}
For the expert user there are many bertini options which can 
improve performance. These can be added 
to the file ``bertiniInput\_trackingOptions'', and one can refer to Appendix~A of the  Bertini user manual for more details. 
\end{remark}
% but we will ingnore them for now.
% Can we adjust the implementation so that if this is not specified it still works?


\subsection{Solving}
To solve the system, we use python2 to run the ``multiregeneration.py'' 
script \emph{from the ``getting-started'' folder}. The multiregeneration 
script will look for input files in the directory from which it is run, 
so make sure that you are in the directory with the system you wish to 
solve. 


\begin{leftbar}
\vspace{-10pt} 
\begin{verbatim}
python2 ../multiregeneration.py
\end{verbatim}\vspace{-10pt} 
\end{leftbar}

If all goes well python will print out ``Done.'' and there will be 
a new directory called ``run''. If there was an error, then the most 
likely cause is that there was an error in one of the input files.

The solutions will be contained in the folder 

\begin{leftbar}
\vspace{-10pt} 
\begin{verbatim}
run/_completed_smooth_solutions/depth_1
\end{verbatim}\vspace{-10pt} 
\end{leftbar}

The ``depth'' refers to how many equations have been solved so far. At 
depth $n$ the first $n+1$ equations have been solved, so for this 
example we look at depth 1. Later we will say more about why this is, 
but for the moment, know that the sulotions are always in the folder 
corresponding to the last depth. Returning to our example, there are two 
files called 

\begin{leftbar}
\vspace{-10pt} 
\begin{verbatim}
solution_tracking_depth_1_gens_1_1_dim_0_varGroup_0_regenLinear_1_pointId_326664877375_788310760051
solution_tracking_depth_1_gens_1_1_dim_0_varGroup_0_regenLinear_1_pointId_918720474422_183602510053 
\end{verbatim}\vspace{-10pt} 
\end{leftbar}
The two file contain approximate complex values for the two solutions of 
the initial system. For example the first file contains the following.


\begin{leftbar}
\vspace{-10pt} 
\begin{verbatim}
    1.999999999999996e+00 -4.107825191113079e-15
    3.000000000000000e+00 0.000000000000000e+00
\end{verbatim}\vspace{-10pt} 
\end{leftbar}

\noindent The file can be read as
\begin{align*}
    x &= 1.999999999999996 \times 10^0 - (4.107825191113079 \times 
    10^{-15})i\\
    y &= 3.000000000000000 \times 10^0 + (0.0000000000000000 \times 
    10^{0})i\\
\end{align*}
which is aproximately the solution $x = 2, y = 3$.


\section{Multiple variable groups}
\subsection{Multihomogeneous B\'{e}zout's Theorem}
To motivate the notion of variable groups, we begin by stating the 
following formulation of B\'{e}zout's Theorem.

\begin{theorem}
Let $f_1, \ldots, f_N$ be polynomials with complex coefficients in $n$ 
variables, and let $d_1, \ldots, d_N$ denote their degrees. If 
$\mathcal{V}(f_1, \ldots, f_N)$ is finite, than its size is at most 
$d_1d_2 \ldots d_N$. 
\end{theorem}

For now we will assume that our system has finitely many solutions.
Therefore the degrees $d_1, \ldots, d_n$ give an upper bound on the size 
of the output. It is not hard to construct examples where the number of 
solutions is exactly this bound, so in the case of general equations of 
degrees $d_1, \ldots, d_n$ this worst case bound cannot be improved.

Here is a simple example to illustrate this bound.
\begin{align*}
    f_1 &= x^2 + xy + x - y\\
    f_2 &= y^2 + 4xy - 2y
\end{align*}
We can verify as in the previous section that this system has exactly 
$d_1d_2 = 4$ solutions.

Let us remove the $x^2$ and $y^2$ terms from the example above.
\begin{align*}
    f_1 &= xy + x - y\\
    f_2 &= 4xy - 2y
\end{align*}
The degrees $d_1$ and $d_2$ have not changed, so the B\'{e}zout bound 
still predicts four solutions. However, removing the square terms 
reduced the number of solutions to two. This is a consequence of the 
Multi-homogenius B\'{e}zout theorem, which we state below.

Say that for each $1 \leq i \leq k$ we have a group of variables 
$\mathbf{x}_i = (x_{i,1}, \ldots, x_{i,n_i})$, for a total of $n := n_1 
+ \ldots + n_k$ variables. Let $f(\mathbf{x}_1, \ldots, 
\mathbf{x}_k)$ denote a polynomail in all $n$ variables. We define the 
\emph{multidegree} of $f$ to be the integer vector $\Deg(f) = 
(\Deg_1(f), \ldots, \Deg_k(f))$ where $\Deg_i(f)$ is the degree of $f$ 
treating all variables except for $\mathbf{x}_i$ as constants.

\begin{theorem}
Let $f_1, \ldots, f_N$ be polynomials with complex coefficients in the 
   variables $\mathbf{x}_1, 
\ldots, \mathbf{x}_n$. Consider the formal expression $\prod_{s = 1}^N 
\sum_{i = 1}^{k} \Deg_i(f_s) \alpha_i$ in indeterminants $\alpha_1, 
\ldots, \alpha_k$, and let $B$ denote the coefficient of the monomial 
$\alpha_1\ldots \alpha_k$. If $\mathcal{V}(f_1, \ldots, f_N)$ is finite, 
than its size is at most $B$.
\end{theorem}

The number $B$ is called the \emph{multi-homogenius B\'{e}zout number}.

Returning to our example, let us define variable groups $\mathbf{x}_1 = 
(x), \mathbf{x}_2 = (y)$. Then $\Deg(f_1) = (1,1)$ and $\Deg(f_2) = 
(1,1)$. From the expression
\[
    (\alpha_1 + \alpha_2)(\alpha_1 + \alpha_2) = \alpha_1^2 + 
   2\alpha_1\alpha_2 + \alpha_2^2
\]
we see that $B = 2$. So if $\mathcal{V}(f_1, f_2)$ is finite, its size is 
at most two.

\subsection{Solving with multiple variable groups}
When solving a polynomial system, if there is a variable group structure 
that gives a low multi-homogenius B\'{e}zout number, then this 
gives us better garunties about the number of solutions we will find. 
Moreover, the program can take advantage of this extra structure to do 
less work.

For an example of how to use variable groups, change into the directory 
called ``multiple\_variable\_groups'', which contains the following 
files.\\

\noindent \textbf{bertiniInput\_variables}
\begin{leftbar}
\vspace{-10pt} 
\begin{verbatim}
    variable_group x; 
    variable_group y; 
\end{verbatim}\vspace{-10pt} 
\end{leftbar}

\noindent \textbf{bertiniInput\_equations}
\begin{leftbar}
\vspace{-10pt} 
\begin{verbatim}
    function f1,f2;
    f1 = x*y + x - y;
    f2 = 4*x*y - 2*y;
\end{verbatim}\vspace{-10pt} 
\end{leftbar}


\noindent \textbf{inputFile.py}
\begin{leftbar}
\vspace{-10pt} 
\begin{verbatim}
    degrees = [[1,1], [1,1]]
\end{verbatim}\vspace{-10pt} 
\end{leftbar}

The only differences when using multiple variable groups are the 
declaration of multiple variable groups in ``bertiniInput\_variables'' 
and the entries of the ``degree'' variable, which now contains the 
multidegrees $Deg(f_1)$ and $Deg(f_2)$.

\noindent As before we run
\begin{leftbar}
\vspace{-10pt} 
\begin{verbatim}
python2 ../multiregeneration.py
\end{verbatim}\vspace{-10pt} 
\end{leftbar}
\noindent and look for the solution files in 
\begin{leftbar}
\vspace{-10pt} 
\begin{verbatim}
run/_completed_smooth_solutions/depth_1
\end{verbatim}\vspace{-10pt} 
\end{leftbar}
\noindent where we find the two solutions.

\section{Solving with homogeneous variable groups}
In this section we demonstrate how to solve systems of homogeneus 
polynomials over complex projective space, which is a central idea in 
algebraic geometry. For a good introduction to 
projective space see chapter 8 sections 1 and 2 of \cite{cox}, or 
appendix A of \cite{silverman}.

Consider the following system of homogenius polynomials, representing 
the intersection of two curves in the projective plane.
\begin{align*}
   f_1 &= y^2z - x^3 + z^3 - xyz &&= 0\\
   f_2 &= yz - x^2 + xy - xz + z^2 &&= 0\\
\end{align*}
Observe that all terms in the first equation are degree three, and all 
term is the second equations are degree two, so these equations are 
indeed homogeneous of degrees two and three. If you input equations that 
are not homogeneous, and then try to solve them over projective space it 
will cause errors, so watch out for this.

Change into the directory 
called ``homogeneous-variable-groups'', which contains the following 
files.\\

\noindent \textbf{bertiniInput\_variables}
\begin{leftbar}
\vspace{-10pt} 
\begin{verbatim}
   hom_variable_group x,y,z;
\end{verbatim}\vspace{-10pt} 
\end{leftbar}

\noindent \textbf{bertiniInput\_equations}
\begin{leftbar}
\vspace{-10pt} 
\begin{verbatim}
   function f1,f2;
   f1 = y^2*z - x^3 + z^3 - x*y*z;
   f2 = y*z - x^2 + x*y - x*z + z^2;
\end{verbatim}\vspace{-10pt} 
\end{leftbar}


\noindent \textbf{inputFile.py}
\begin{leftbar}
\vspace{-10pt} 
\begin{verbatim}
   degrees = [[3], [2]]
\end{verbatim}\vspace{-10pt} 
\end{leftbar}

There are two notable differences: (1) our equations are homogeneous, and 
(2) we have declared a ``hom\_variable\_group''.

\noindent After running the program
\begin{leftbar}
\vspace{-10pt} 
\begin{verbatim}
python2 ../multiregeneration.py
\end{verbatim}\vspace{-10pt} 
\end{leftbar}
\noindent the output in
\begin{leftbar}
\vspace{-10pt} 
\begin{verbatim}
run/_completed_smooth_solutions/depth_1
\end{verbatim}\vspace{-10pt} 
\end{leftbar}
\noindent will be give the homogenius coordinates of the six 
solutions.

\begin{remark}
One can also better performance by having multiple homogeneous groups or a mixture of homogeneous and affine groups. 
\end{remark}

\section{Positive dimensional components}
In this section we will introduce some of the language of 
algebraic geometry and numerical algebraic geometry, so that we can 
describe how the program handles the case where the solution set is 
infinite (i.e. that it contains positive dimensional components).

Recall that a set $A \subset \C^n$ is \emph{algebraic} or \emph{Zariski 
closed} if it is of the form $\mathcal{V}(f_1, \ldots, f_N)$ for 
polynomials $f_i$. Similarly, a set $A \subset \PP^n$ is 
\emph{algebraic} or \emph{Zariski closed} if it is of the form 
$\mathcal{V}(f_1, \ldots, f_N)$ for 
homogeneous polynomials $f_i$. If an algebraic set is the union of 
finitly many algebraic proper subsets, the it is \emph{reducible}. An 
algebraic set that is not reducible is \emph{irreducible}. If $A$ is an 
algebraic set, then a maximal irreducible algebraic subset of $A$ 
is called an \emph{irreducible component of $A$}, or simply a 
\emph{component of $A$}.

The following fact is typically proven in a first commutative algebra or 
algebraic geometry course.
\begin{theorem}
   Every algebraic set in $\C^n$ or $\PP^n$ is the union of finitely 
   many irreducible components.
\end{theorem}

In the case where a polynomial system has infinitely many solutions, it is 
often best to describe each component separately. As a simple example, 
cosider the following.

\begin{align*}
   f_1 &= (y-x^2)(x-1) &&= 0\\
   f_2 &= (y-x^2)(y) &&= 0
\end{align*}

The solutions consist of a parabola and a point, which are the two 
irreducible components. This system can be found in the 
``positive-dimensional'' folder. The following files contain the solutions.
\begin{leftbar}
\vspace{-10pt} 
\begin{verbatim}
      solution_tracking_depth_1_gens_1_1_dim_0_varGroup_0_regenLinear_1_pointId_151979748598_138051236175
      solution_vanishing_depth_1_gens_1_0_dim_1_pointId_11020904120_11020904120
      solution_vanishing_depth_1_gens_1_0_dim_1_pointId_462642055403_462642055403
\end{verbatim}\vspace{-10pt} 
\end{leftbar}

The coordinates of the isolated point are contained in the files whose 
name contains the string ``dim\_0''. The other two files, whose names 
contain the string ``dim\_1'' are two points on the one dimensional 
parabola, which is the other irreducible component. Which two points of 
the parabola were chosen, and why? To answer this question, we introduce 
some language from numerical algebraic geometry.

By a \emph{hyperplane in $\C^n$}, we mean a variety of the form 
$\mathcal{V}(a_0 + a_1x_1 + \ldots + a_nx_n)$ where one of $a_1, \ldots, 
a_n$ is not zero. By a \emph{hyperplane in 
$\PP^n$} we mean a variety of the form $\mathcal{V}(a_0x_0 + a_1x_1 
+ \ldots + a_nx_n)$ where one of $a_0, \ldots, a_n$ is not zero. 
Intuitively, a \emph{general hyperplane} is a 
hyperplane where the parameters $a_i$ are choosen at random, and satisfy 
no special relations. Here is a more precise definition. Note that 
parameters $a_i$ and $a'_i$ define the same hyperplane in $\PP^n$ if and 
only if there exists $\lambda \in \C$ such that $\lambda a_i = a'_i$. Therefore 
there is a bijection between hyperplanes in $\PP^n$ and equivilance 
classes of $(a_0, \ldots, a_n)$ up to scaling, where one $a_i$ is not 
zero. This is to say that the set of hyperplanes in $\PP^n$ can itself be 
identified with another copy of $\PP^n$ with homogeneous coordinates 
$a_i$. To avoid confusion with the original $\PP^n$, we will denote the 
space of hyperplanes in $\PP^n$ by $(\PP^n)^\vee$. When we say that a 
generic hyperplane in $\PP^n$ has a certain property, we mean that the 
set of hyperplanes that does not have this property is a Zariski closed 
set in $(\PP^n)^\vee$.

\begin{remark}
   One can show that Zariski closed sets have measure zero, so if a 
   generic hyperplane has a certain property, then all hyperplanes away 
   from a set of measure zero have that property.
\end{remark}
\begin{remark}
   The set of hyperplanes in $\C^n$ does not have the structure of 
   $\PP^n$, because for $\mathcal{V}(a_0 + a_1x_1 + \ldots + a_nx_n)$ to 
   be a well defined hyperplane, we need for some $a_i$ other than $a_0$ 
   to be nonzero. From this it follows that the set of hyperplanes in 
   $\C^n$ has the structure of $(\PP^n)^\vee - \mathcal{V}(a_1, \ldots, 
   a_n)$. A generic hyperplane in $\C^n$ can be defined in a similar 
   way.
\end{remark}

The following fact is often proved with the use of more powerful 
theorems such as Bertini's theorem and Bezout's theorem, but we want to 
get down to business, so we will take it for granted.

\begin{theorem}
   Let $X$ be an irreducible algebraic variety in $\C^n$ or $\PP^n$. 
   Then there is unique number $d$ such that the intersection of $X$ 
   with $n-d$ generic hyperplanes is finite and nonempty. Moreover, the 
   size of the intersection does not depend on the choice of generic 
   hyperplanes.
\end{theorem}

The number $d$ we define to be the \emph{dimension of $X$}, and the number size 
of the intersection is the \emph{degree of $X$}. \footnote{The degree of 
a variety in $\C^n$ or $\PP^n$ is not an isomorphism invariant, since it 
depends on the embedding.}

Returning to the example above, the two points on the parabola which 
were outputed were the intersection of the parabola with one generic 
hyperplane. As we would expect, the fact that there are two of them 
means that the parabola has degree two. One of the main ideas 
in numerical algebraic geometry is that many questions about a $d$ 
dimensional irreducible variety in $\C^n$ or $\PP^n$ can be answered by knowing the 
its intersection with $n-d$ generic hyperplanes. This intersection is 
called a \emph{witness set for $X$}. For more information 
about this, and examples of other questions which can be answered with 
witness sets, see...

\section{Tips for large computations}

One of the main advantages of numerical methods for solving polynomial 
systems (over Gr\"{o}bner basis methods for instance) is that they are 
very parallelizable. To use multiple processors to solve a system, we 
can set the ``maxProcesses'' variable in ``inputFile.py''.

\noindent \textbf{inputFile.py}
\begin{leftbar}
\vspace{-10pt} 
\begin{verbatim}
   degrees = [[3], [2]]
   maxProcesses = 4
\end{verbatim}\vspace{-10pt} 
\end{leftbar}

Adding more processes will only speed up the calculation if the number 
you choose is less than or equal to the number of CPU cores on your 
computer, and in fact adding more processes than you have cores will 
slow things down.

If you do not have enough time or space to find all of the solution to a 
particular system, then it can sometimes still be worth it to find as 
many solutions as you can. If this is the case, the it is recommended to 
use the following option in ``inputFile.py''
\noindent \textbf{inputFile.py}
\begin{leftbar}
\vspace{-10pt} 
\begin{verbatim}
   degrees = [[3], [2]]
   explorationOrder = "depthFirst"
\end{verbatim}\vspace{-10pt} 
\end{leftbar}
Setting this option will not decrease the time it takes for the program 
to finish, however it will increase the number of solutions 
found after any given time. Here is a vague explanation as to why: The 
nature of the algorithm is that ``solutions at depth $n$'' lead to 
``solutions at depth $n+1$.'' The solutions at the last depth are the 
actual solutions to the system. In this way, the program first populates 
one depth with solutions, and then moves to the next. Setting the 
exploration order to ``depthFirst'' will ensure that if a solution is 
found at depth $n$, then it is immediately used to find a solution at 
depth $n+1$, before looking for other solutions at depth $n$. The result 
is that the maximum number full depth solutions are found after any 
given time.

In the directory ``large'' there is a system of 10 polynomials, all of 
degree $(1,1)$ with respect to variable groups $x_0, \ldots, x_4$ and 
$y_0, \ldots, y_4$. This computation should take on the order of 30 
seconds, so you can experiment with parallel processing, depth first 
order, and using multiple variable groups versus a single variable 
group.


\red{
When possible bibtex information from references 
should be selected from Mathscinet
\url{https://search.library.wisc.edu/search/database?q=mathscinet}

\noindent Here is a link to learn how to use bibtex\newline
\url{https://www.unf.edu/~wkloster/latex/bib.html}.

}
\begin{thebibliography}{9}
\bibitem{cox} 
David Cox, John Little, and Donal O'shea.
\textit{Ideals, Varieties, and Algorithms}. 

\bibitem{silverman} 
Josheph H. Silverman and John Tate.
\textit{Rational Points on Elliptic Curves}. 
 
\end{thebibliography}

\end{document}
